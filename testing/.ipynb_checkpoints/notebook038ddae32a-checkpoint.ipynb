{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T18:05:22.769523Z",
     "iopub.status.busy": "2022-02-19T18:05:22.768661Z",
     "iopub.status.idle": "2022-02-19T18:05:37.818589Z",
     "shell.execute_reply": "2022-02-19T18:05:37.817265Z",
     "shell.execute_reply.started": "2022-02-19T18:05:22.769421Z"
    }
   },
   "source": [
    "# Bengali Fake News Classification\n",
    "```\n",
    "    আমি বাংলায় গান গাই\n",
    "    আমি বাংলার গান গাই।\n",
    "    আমি আমার আমিকে চিরদিন\n",
    "    এই বাংলায় খুঁজে পাই।\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:32.543349Z",
     "iopub.status.busy": "2022-02-20T19:05:32.542454Z",
     "iopub.status.idle": "2022-02-20T19:05:32.547447Z",
     "shell.execute_reply": "2022-02-20T19:05:32.546438Z",
     "shell.execute_reply.started": "2022-02-20T19:05:32.543299Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:34.147868Z",
     "iopub.status.busy": "2022-02-20T19:05:34.147387Z",
     "iopub.status.idle": "2022-02-20T19:05:38.859204Z",
     "shell.execute_reply": "2022-02-20T19:05:38.858396Z",
     "shell.execute_reply.started": "2022-02-20T19:05:34.147813Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "auth = pd.read_csv(\"../input/banfakenews/Authentic-48K.csv\")\n",
    "fake = pd.read_csv(\"../input/banfakenews/Fake-1K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:38.861064Z",
     "iopub.status.busy": "2022-02-20T19:05:38.860803Z",
     "iopub.status.idle": "2022-02-20T19:05:38.88014Z",
     "shell.execute_reply": "2022-02-20T19:05:38.879318Z",
     "shell.execute_reply.started": "2022-02-20T19:05:38.861029Z"
    }
   },
   "outputs": [],
   "source": [
    "auth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:38.881748Z",
     "iopub.status.busy": "2022-02-20T19:05:38.881442Z",
     "iopub.status.idle": "2022-02-20T19:05:38.892603Z",
     "shell.execute_reply": "2022-02-20T19:05:38.891961Z",
     "shell.execute_reply.started": "2022-02-20T19:05:38.881713Z"
    }
   },
   "outputs": [],
   "source": [
    "fake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:39.328096Z",
     "iopub.status.busy": "2022-02-20T19:05:39.327762Z",
     "iopub.status.idle": "2022-02-20T19:05:39.826755Z",
     "shell.execute_reply": "2022-02-20T19:05:39.826046Z",
     "shell.execute_reply.started": "2022-02-20T19:05:39.328058Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_bar(column, title, top=100):\n",
    "  plt.figure(figsize=(20,5))\n",
    "  column[:top].plot(kind='bar')\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"ID\")\n",
    "  plt.ylabel(\"Count\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def show_dist(column):\n",
    "  plt.figure(figsize=(10,5))\n",
    "  sns.distplot(column)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Headline Length and Content Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:42.829326Z",
     "iopub.status.busy": "2022-02-20T19:05:42.829074Z",
     "iopub.status.idle": "2022-02-20T19:05:46.140059Z",
     "shell.execute_reply": "2022-02-20T19:05:46.139385Z",
     "shell.execute_reply.started": "2022-02-20T19:05:42.829297Z"
    }
   },
   "outputs": [],
   "source": [
    "auth['head_lenght'] = auth.headline.apply(lambda x : len(x.split()))\n",
    "auth['content_head_lenght'] = auth.content.apply(lambda x : len(x.split()))\n",
    "\n",
    "\n",
    "show_bar(auth.head_lenght, \"Authentic Headlines Length TOP 100\")\n",
    "print(\"\")\n",
    "show_bar(auth.content_head_lenght, \"Authentic Content Length TOP 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:46.141999Z",
     "iopub.status.busy": "2022-02-20T19:05:46.141736Z",
     "iopub.status.idle": "2022-02-20T19:05:47.305093Z",
     "shell.execute_reply": "2022-02-20T19:05:47.304361Z",
     "shell.execute_reply.started": "2022-02-20T19:05:46.141964Z"
    }
   },
   "outputs": [],
   "source": [
    "show_dist(auth.head_lenght)\n",
    "print(\"\")\n",
    "show_dist(auth.content_head_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:47.306961Z",
     "iopub.status.busy": "2022-02-20T19:05:47.306488Z",
     "iopub.status.idle": "2022-02-20T19:05:49.190541Z",
     "shell.execute_reply": "2022-02-20T19:05:49.18987Z",
     "shell.execute_reply.started": "2022-02-20T19:05:47.306918Z"
    }
   },
   "outputs": [],
   "source": [
    "fake['head_lenght'] = fake.headline.apply(lambda x : len(x.split()))\n",
    "fake['content_head_lenght'] = fake.content.apply(lambda x : len(x.split()))\n",
    "\n",
    "show_bar(fake.head_lenght, \"Fake Headlines Length TOP 100\")\n",
    "print(\"\")\n",
    "show_bar(fake.content_head_lenght, \"Fake Content Length TOP 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:51.758688Z",
     "iopub.status.busy": "2022-02-20T19:05:51.758422Z",
     "iopub.status.idle": "2022-02-20T19:05:52.27318Z",
     "shell.execute_reply": "2022-02-20T19:05:52.272312Z",
     "shell.execute_reply.started": "2022-02-20T19:05:51.758659Z"
    }
   },
   "outputs": [],
   "source": [
    "show_dist(fake.head_lenght)\n",
    "print(\"\")\n",
    "show_dist(fake.content_head_lenght)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:54.959795Z",
     "iopub.status.busy": "2022-02-20T19:05:54.958924Z",
     "iopub.status.idle": "2022-02-20T19:05:55.907999Z",
     "shell.execute_reply": "2022-02-20T19:05:55.907172Z",
     "shell.execute_reply.started": "2022-02-20T19:05:54.959747Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://www.easynepalityping.com/resource/font/bangla/06-nikosh-bangla-font.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:56.70295Z",
     "iopub.status.busy": "2022-02-20T19:05:56.702665Z",
     "iopub.status.idle": "2022-02-20T19:05:57.406568Z",
     "shell.execute_reply": "2022-02-20T19:05:57.405764Z",
     "shell.execute_reply.started": "2022-02-20T19:05:56.702917Z"
    }
   },
   "outputs": [],
   "source": [
    "!unzip 06-nikosh-bangla-font.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:05:58.193429Z",
     "iopub.status.busy": "2022-02-20T19:05:58.192665Z",
     "iopub.status.idle": "2022-02-20T19:05:58.237577Z",
     "shell.execute_reply": "2022-02-20T19:05:58.236884Z",
     "shell.execute_reply.started": "2022-02-20T19:05:58.193388Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "def plot_world(text):\n",
    "\n",
    "    wordcloud = WordCloud(width = 500, height = 500, \n",
    "                    background_color ='black', \n",
    "                    font_path=\"Nikosh.ttf\",\n",
    "                    min_font_size = 10).generate(text) \n",
    "\n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (5, 5), facecolor = 'k', edgecolor = 'k' ) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:00.183633Z",
     "iopub.status.busy": "2022-02-20T19:06:00.182841Z",
     "iopub.status.idle": "2022-02-20T19:06:01.654588Z",
     "shell.execute_reply": "2022-02-20T19:06:01.65375Z",
     "shell.execute_reply.started": "2022-02-20T19:06:00.183595Z"
    }
   },
   "outputs": [],
   "source": [
    "s= \" \".join(auth.headline[:100])\n",
    "plot_world(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:02.088513Z",
     "iopub.status.busy": "2022-02-20T19:06:02.087677Z",
     "iopub.status.idle": "2022-02-20T19:06:03.082667Z",
     "shell.execute_reply": "2022-02-20T19:06:03.08177Z",
     "shell.execute_reply.started": "2022-02-20T19:06:02.088458Z"
    }
   },
   "outputs": [],
   "source": [
    "s= \" \".join(fake.headline[:100])\n",
    "plot_world(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:05.91743Z",
     "iopub.status.busy": "2022-02-20T19:06:05.917171Z",
     "iopub.status.idle": "2022-02-20T19:06:16.51637Z",
     "shell.execute_reply": "2022-02-20T19:06:16.515309Z",
     "shell.execute_reply.started": "2022-02-20T19:06:05.917402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bnlp_toolkit\n",
      "  Downloading bnlp_toolkit-3.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting sklearn-crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\meera\\anaconda3\\lib\\site-packages (from bnlp_toolkit) (1.9.1)\n",
      "Collecting wasabi\n",
      "  Downloading wasabi-1.1.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\meera\\anaconda3\\lib\\site-packages (from bnlp_toolkit) (4.64.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\meera\\anaconda3\\lib\\site-packages (from bnlp_toolkit) (0.1.97)\n",
      "Requirement already satisfied: numpy in c:\\users\\meera\\anaconda3\\lib\\site-packages (from bnlp_toolkit) (1.21.5)\n",
      "Collecting gensim==4.0.1\n",
      "  Downloading gensim-4.0.1.tar.gz (23.1 MB)\n",
      "     ---------------------------------------- 23.1/23.1 MB 4.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: nltk in c:\\users\\meera\\anaconda3\\lib\\site-packages (from bnlp_toolkit) (3.7)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\meera\\anaconda3\\lib\\site-packages (from gensim==4.0.1->bnlp_toolkit) (5.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\meera\\anaconda3\\lib\\site-packages (from nltk->bnlp_toolkit) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\meera\\anaconda3\\lib\\site-packages (from nltk->bnlp_toolkit) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\meera\\anaconda3\\lib\\site-packages (from nltk->bnlp_toolkit) (1.1.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\meera\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.10)\n",
      "Collecting python-crfsuite>=0.8.3\n",
      "  Downloading python_crfsuite-0.9.8-cp39-cp39-win_amd64.whl (158 kB)\n",
      "     -------------------------------------- 158.6/158.6 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\meera\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\meera\\anaconda3\\lib\\site-packages (from tqdm->bnlp_toolkit) (0.4.5)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'done'\n",
      "  Created wheel for gensim: filename=gensim-4.0.1-cp39-cp39-win_amd64.whl size=23772775 sha256=93e7f2d75bb5168b2e7072dc1b9a371e460bf95ba6bb08010720abefe1bab0b1\n",
      "  Stored in directory: c:\\users\\meera\\appdata\\local\\pip\\cache\\wheels\\20\\74\\75\\72ec1172891bdecb4ee73fbc2c71d5a150f165b1d0c2ea04e1\n",
      "Successfully built gensim\n",
      "Installing collected packages: python-crfsuite, colorama, wasabi, gensim, sklearn-crfsuite, bnlp_toolkit\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.5\n",
      "    Uninstalling colorama-0.4.5:\n",
      "      Successfully uninstalled colorama-0.4.5\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.1.2\n",
      "    Uninstalling gensim-4.1.2:\n",
      "      Successfully uninstalled gensim-4.1.2\n",
      "Successfully installed bnlp_toolkit-3.2.0 colorama-0.4.6 gensim-4.0.1 python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6 wasabi-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install bnlp_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:16.519052Z",
     "iopub.status.busy": "2022-02-20T19:06:16.518712Z",
     "iopub.status.idle": "2022-02-20T19:06:17.269089Z",
     "shell.execute_reply": "2022-02-20T19:06:17.267053Z",
     "shell.execute_reply.started": "2022-02-20T19:06:16.519011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আমি', 'বাংলায়', 'গান', 'গাই', 'আমি', 'বাংলার', 'গান', 'গাই', '।', 'আমি', 'আমার', 'আমিকে', 'চিরদিন', 'এই', 'বাংলায়', 'খুঁজে', 'পাই', '।']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meera\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from bnlp import BasicTokenizer\n",
    "tokenizer = BasicTokenizer()\n",
    "\n",
    "s = \"\"\"আমি বাংলায় গান গাই\n",
    "    আমি বাংলার গান গাই।\n",
    "    আমি আমার আমিকে চিরদিন\n",
    "    এই বাংলায় খুঁজে পাই।\"\"\"\n",
    "\n",
    "print(tokenizer.tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:17.27106Z",
     "iopub.status.busy": "2022-02-20T19:06:17.270723Z",
     "iopub.status.idle": "2022-02-20T19:06:17.276011Z",
     "shell.execute_reply": "2022-02-20T19:06:17.275291Z",
     "shell.execute_reply.started": "2022-02-20T19:06:17.270966Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_corpus(texts):\n",
    "    corpus=[]\n",
    "\n",
    "    for txt in texts:\n",
    "      tokens = tokenizer.tokenize(txt)\n",
    "      corpus.extend(tokens)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:17.278638Z",
     "iopub.status.busy": "2022-02-20T19:06:17.27817Z",
     "iopub.status.idle": "2022-02-20T19:06:17.445792Z",
     "shell.execute_reply": "2022-02-20T19:06:17.444904Z",
     "shell.execute_reply.started": "2022-02-20T19:06:17.2786Z"
    }
   },
   "outputs": [],
   "source": [
    "auth_corpus = create_corpus(auth.headline[:1000])\n",
    "print(\"Total auth tokens in 1000\", len(auth_corpus))\n",
    "\n",
    "fake_corpus = create_corpus(fake.headline[:1000])\n",
    "print(\"Total auth tokens in 1000\", len(fake_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:17.447571Z",
     "iopub.status.busy": "2022-02-20T19:06:17.447253Z",
     "iopub.status.idle": "2022-02-20T19:06:17.453962Z",
     "shell.execute_reply": "2022-02-20T19:06:17.453177Z",
     "shell.execute_reply.started": "2022-02-20T19:06:17.447522Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Nikosh.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4616\\3394690795.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfont_manager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# set font\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfont_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nikosh.ttf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'font.family'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Nikosh'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'font.sans-serif'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Nikosh'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36maddfont\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1090\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafmlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mft2font\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFT2Font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m             \u001b[0mprop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mttfFontProperty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mttflist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Nikosh.ttf'"
     ]
    }
   ],
   "source": [
    "from matplotlib import font_manager\n",
    "# set font\n",
    "font_manager.fontManager.addfont(\"Nikosh.ttf\")\n",
    "plt.rcParams['font.family'] = 'Nikosh'\n",
    "plt.rcParams['font.sans-serif']=['Nikosh']\n",
    "plt.rcParams['axes.unicode_minus']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:17.456179Z",
     "iopub.status.busy": "2022-02-20T19:06:17.455565Z",
     "iopub.status.idle": "2022-02-20T19:06:17.465935Z",
     "shell.execute_reply": "2022-02-20T19:06:17.465078Z",
     "shell.execute_reply.started": "2022-02-20T19:06:17.45614Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import  Counter\n",
    "from bnlp.corpus import stopwords\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "def show_stop_words(corpus, length=20):\n",
    "  dic = defaultdict(int)\n",
    "\n",
    "  for word in corpus:\n",
    "      if word in stopwords:\n",
    "          dic[word]+=1\n",
    "\n",
    "  top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:length]\n",
    "  x,y=zip(*top)\n",
    "  print(x)\n",
    "  print(y)\n",
    "  plt.figure(figsize=(10,5))\n",
    "  plt.bar(x,y)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:17.467841Z",
     "iopub.status.busy": "2022-02-20T19:06:17.467474Z",
     "iopub.status.idle": "2022-02-20T19:06:17.766417Z",
     "shell.execute_reply": "2022-02-20T19:06:17.765643Z",
     "shell.execute_reply.started": "2022-02-20T19:06:17.467805Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4616\\3832671263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'show_stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "show_stop_words(auth_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:17.768866Z",
     "iopub.status.busy": "2022-02-20T19:06:17.768581Z",
     "iopub.status.idle": "2022-02-20T19:06:18.074408Z",
     "shell.execute_reply": "2022-02-20T19:06:18.072697Z",
     "shell.execute_reply.started": "2022-02-20T19:06:17.768814Z"
    }
   },
   "outputs": [],
   "source": [
    "show_stop_words(fake_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:20.276596Z",
     "iopub.status.busy": "2022-02-20T19:06:20.276098Z",
     "iopub.status.idle": "2022-02-20T19:06:20.282648Z",
     "shell.execute_reply": "2022-02-20T19:06:20.28186Z",
     "shell.execute_reply.started": "2022-02-20T19:06:20.276557Z"
    }
   },
   "outputs": [],
   "source": [
    "from bnlp.corpus import stopwords, punctuations, digits\n",
    "\n",
    "def filters(corpus):\n",
    "  res = []\n",
    "  for i in corpus:\n",
    "    if i in stopwords:\n",
    "      continue\n",
    "\n",
    "    if i in punctuations + '‘' + '’':\n",
    "      continue\n",
    "\n",
    "    if i in digits:\n",
    "      continue\n",
    "\n",
    "    res.append(i)\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:22.00834Z",
     "iopub.status.busy": "2022-02-20T19:06:22.007292Z",
     "iopub.status.idle": "2022-02-20T19:06:22.093749Z",
     "shell.execute_reply": "2022-02-20T19:06:22.093097Z",
     "shell.execute_reply.started": "2022-02-20T19:06:22.00829Z"
    }
   },
   "outputs": [],
   "source": [
    "auth_corpus_filtered = filters(auth_corpus)\n",
    "fake_corpus_filtered = filters(fake_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:23.102143Z",
     "iopub.status.busy": "2022-02-20T19:06:23.101521Z",
     "iopub.status.idle": "2022-02-20T19:06:23.108236Z",
     "shell.execute_reply": "2022-02-20T19:06:23.107316Z",
     "shell.execute_reply.started": "2022-02-20T19:06:23.102101Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_words(corpus):\n",
    "  dic = defaultdict(int)\n",
    "\n",
    "  for word in corpus:\n",
    "      dic[word] +=1\n",
    "\n",
    "  top = sorted(dic.items(), key=lambda x:x[1],reverse=True)\n",
    "  x,y=zip(*top)\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:27.12382Z",
     "iopub.status.busy": "2022-02-20T19:06:27.123554Z",
     "iopub.status.idle": "2022-02-20T19:06:27.132949Z",
     "shell.execute_reply": "2022-02-20T19:06:27.132058Z",
     "shell.execute_reply.started": "2022-02-20T19:06:27.123788Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = get_top_words(auth_corpus_filtered)\n",
    "\n",
    "print(\"Top 10 words\")\n",
    "print(x[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:28.758737Z",
     "iopub.status.busy": "2022-02-20T19:06:28.758247Z",
     "iopub.status.idle": "2022-02-20T19:06:28.768713Z",
     "shell.execute_reply": "2022-02-20T19:06:28.76795Z",
     "shell.execute_reply.started": "2022-02-20T19:06:28.758697Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = get_top_words(fake_corpus_filtered)\n",
    "\n",
    "print(\"Top 10 words\")\n",
    "print(x[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:08:00.454669Z",
     "iopub.status.busy": "2022-02-20T19:08:00.45408Z",
     "iopub.status.idle": "2022-02-20T19:08:00.460078Z",
     "shell.execute_reply": "2022-02-20T19:08:00.459017Z",
     "shell.execute_reply.started": "2022-02-20T19:08:00.454631Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Datasets\n",
    "- Dataset Info: Datasets contain `48678` authentic news and `1299` fake news. For this experiment, instead of all authentic news, only 5 times of fake news was used.\n",
    "- And only consider the first 100 words (including headline and content)\n",
    "\n",
    "- On datasets: Both headline and content of news were used. And manually a separator was added also `[SEP]`.\n",
    "\n",
    "> BERT model is designed in such a way that the sentence has to start with the [CLS] token and end with the [SEP] token.\n",
    "If we want to make separation of two sentences we can use [SEP] between sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test split: \n",
    "(only 20% data used for testing)\n",
    "- Total Dataset size: 10392\n",
    "- Total train size: 8313\n",
    "- Test train size: 2079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:07:27.930523Z",
     "iopub.status.busy": "2022-02-20T19:07:27.929938Z",
     "iopub.status.idle": "2022-02-20T19:07:27.936957Z",
     "shell.execute_reply": "2022-02-20T19:07:27.935912Z",
     "shell.execute_reply.started": "2022-02-20T19:07:27.930485Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8728\\2994654967.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mNewsDatasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         self.config = {\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class NewsDatasets(Dataset):\n",
    "    def __init__(self, data, max_length=100):\n",
    "        self.data = data\n",
    "        \n",
    "        self.config = {\n",
    "            \"max_length\": max_length,\n",
    "            \"padding\": \"max_length\",\n",
    "            \"return_tensors\": \"pt\",\n",
    "            \"truncation\": True,\n",
    "            \"add_special_tokens\": True\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        value = self.data.iloc[idx]\n",
    "        return value['text'], value['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:40:39.456217Z",
     "iopub.status.busy": "2022-02-20T19:40:39.455602Z",
     "iopub.status.idle": "2022-02-20T19:40:42.759541Z",
     "shell.execute_reply": "2022-02-20T19:40:42.758779Z",
     "shell.execute_reply.started": "2022-02-20T19:40:39.456178Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/banfakenews/Authentic-48K.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5892\\990619128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/banfakenews/Authentic-48K.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/banfakenews/Fake-1K.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/banfakenews/Authentic-48K.csv'"
     ]
    }
   ],
   "source": [
    "auth = pd.read_csv(\"../input/banfakenews/Authentic-48K.csv\")\n",
    "fake = pd.read_csv(\"../input/banfakenews/Fake-1K.csv\")\n",
    "\n",
    "df = auth[:fake.shape[0]* 7]\n",
    "df = df.append(fake)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:39.015271Z",
     "iopub.status.busy": "2022-02-20T19:06:39.015001Z",
     "iopub.status.idle": "2022-02-20T19:06:39.027441Z",
     "shell.execute_reply": "2022-02-20T19:06:39.026726Z",
     "shell.execute_reply.started": "2022-02-20T19:06:39.015236Z"
    }
   },
   "outputs": [],
   "source": [
    "from bnlp import BasicTokenizer\n",
    "from bnlp.corpus import stopwords, punctuations, letters, digits\n",
    "\n",
    "btokenizer = BasicTokenizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = btokenizer.tokenize(text)\n",
    "    filtered = []\n",
    "    for i in tokens:\n",
    "        if i in stopwords:\n",
    "            continue\n",
    "    \n",
    "        if i in punctuations + '‘' + '’':\n",
    "            continue\n",
    "    \n",
    "        filtered.append(i)\n",
    "    \n",
    "    return \" \".join(filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:06:39.209358Z",
     "iopub.status.busy": "2022-02-20T19:06:39.208809Z",
     "iopub.status.idle": "2022-02-20T19:07:20.706445Z",
     "shell.execute_reply": "2022-02-20T19:07:20.705684Z",
     "shell.execute_reply.started": "2022-02-20T19:06:39.209327Z"
    }
   },
   "outputs": [],
   "source": [
    "df['head'] = df.headline.apply(clean_text)\n",
    "df['con'] = df.content.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:07:20.708114Z",
     "iopub.status.busy": "2022-02-20T19:07:20.70784Z",
     "iopub.status.idle": "2022-02-20T19:07:20.725641Z",
     "shell.execute_reply": "2022-02-20T19:07:20.724961Z",
     "shell.execute_reply.started": "2022-02-20T19:07:20.708077Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=121, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8728\\2785790138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_set_1.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_set_1.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_set_1.csv\")\n",
    "test_df = pd.read_csv(\"test_set_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T18:43:15.929478Z",
     "iopub.status.busy": "2022-02-20T18:43:15.929154Z",
     "iopub.status.idle": "2022-02-20T18:43:15.940591Z",
     "shell.execute_reply": "2022-02-20T18:43:15.939654Z",
     "shell.execute_reply.started": "2022-02-20T18:43:15.929442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096, 1032)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:07:34.195033Z",
     "iopub.status.busy": "2022-02-20T19:07:34.194751Z",
     "iopub.status.idle": "2022-02-20T19:07:34.201213Z",
     "shell.execute_reply": "2022-02-20T19:07:34.200337Z",
     "shell.execute_reply.started": "2022-02-20T19:07:34.195001Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = NewsDatasets(train_df)\n",
    "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:07:36.153728Z",
     "iopub.status.busy": "2022-02-20T19:07:36.153465Z",
     "iopub.status.idle": "2022-02-20T19:07:36.160531Z",
     "shell.execute_reply": "2022-02-20T19:07:36.159782Z",
     "shell.execute_reply.started": "2022-02-20T19:07:36.153697Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = NewsDatasets(test_df)\n",
    "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    " `Bert` stands for Bidirectional Encoder Representations from Transformers used in this experiment with two additional `Fully Connected` Layers. \n",
    " \n",
    " For this experiment, [Bangla Bert](https://huggingface.co/sagorsarker/bangla-bert-base) pretrained model was used.\n",
    "\n",
    "#### FC layers\n",
    "- First Linear Layer: IO(768 -> 128)\n",
    "- Second Linear Layer: IO(128 -> 2)\n",
    "\n",
    "#### Additionals\n",
    "- Activation Fuction: Relu\n",
    "- Dropout: 20%\n",
    "- Optimizer: AdamW\n",
    "- Loss: CrossEntropyLoss\n",
    "- Scheduler: StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:28:41.433732Z",
     "iopub.status.busy": "2022-02-20T19:28:41.433475Z",
     "iopub.status.idle": "2022-02-20T19:28:41.440948Z",
     "shell.execute_reply": "2022-02-20T19:28:41.440265Z",
     "shell.execute_reply.started": "2022-02-20T19:28:41.433704Z"
    }
   },
   "outputs": [],
   "source": [
    "class NewsBert(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(NewsBert, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768, 128)\n",
    "\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(128, 5)  \n",
    "\n",
    "    # define the forward pass\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        # pass the inputs to the model\n",
    "        out = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        x = self.fc1(out[1])\n",
    "        x = self.relu(x)\n",
    "        # output layer\n",
    "        x = self.fc2(self.dropout(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:40:50.347687Z",
     "iopub.status.busy": "2022-02-20T19:40:50.347026Z",
     "iopub.status.idle": "2022-02-20T19:40:56.73157Z",
     "shell.execute_reply": "2022-02-20T19:40:56.730858Z",
     "shell.execute_reply.started": "2022-02-20T19:40:50.347649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = \"sagorsarker/bangla-bert-base\"\n",
    "bert = BertModel.from_pretrained(bert_model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T15:48:50.154265Z",
     "iopub.status.busy": "2022-02-20T15:48:50.154015Z",
     "iopub.status.idle": "2022-02-20T15:48:50.157584Z",
     "shell.execute_reply": "2022-02-20T15:48:50.15689Z",
     "shell.execute_reply.started": "2022-02-20T15:48:50.154229Z"
    }
   },
   "outputs": [],
   "source": [
    "# for param in bert.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:40:56.733407Z",
     "iopub.status.busy": "2022-02-20T19:40:56.73313Z",
     "iopub.status.idle": "2022-02-20T19:40:56.909004Z",
     "shell.execute_reply": "2022-02-20T19:40:56.908307Z",
     "shell.execute_reply.started": "2022-02-20T19:40:56.733367Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NewsBert(bert)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:28:46.43981Z",
     "iopub.status.busy": "2022-02-20T19:28:46.439117Z",
     "iopub.status.idle": "2022-02-20T19:28:46.461639Z",
     "shell.execute_reply": "2022-02-20T19:28:46.460913Z",
     "shell.execute_reply.started": "2022-02-20T19:28:46.439776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2169,  2492,  9294,  2552, 13985,  1014,   102,   102]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "tensor([[-0.0721, -0.1325, -0.1913,  0.1571, -0.0759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = \"আমি বাংলায় গান গাই। [SEP]\"\n",
    "t = tokenizer.encode_plus(s, return_tensors=\"pt\").to(device)\n",
    "print(t)\n",
    "out = model(**t)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:40:58.051416Z",
     "iopub.status.busy": "2022-02-20T19:40:58.050734Z",
     "iopub.status.idle": "2022-02-20T19:40:58.05936Z",
     "shell.execute_reply": "2022-02-20T19:40:58.058672Z",
     "shell.execute_reply.started": "2022-02-20T19:40:58.051379Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:41:03.628477Z",
     "iopub.status.busy": "2022-02-20T19:41:03.628227Z",
     "iopub.status.idle": "2022-02-20T19:41:03.637187Z",
     "shell.execute_reply": "2022-02-20T19:41:03.634912Z",
     "shell.execute_reply.started": "2022-02-20T19:41:03.628449Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, config):\n",
    "    model.train()  # prep model for training\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        text, labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        inputs = tokenizer.batch_encode_plus(\n",
    "            text, **config\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        token_type_ids = inputs['token_type_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # move things to model\n",
    "        logs = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = criterion(logs, labels)\n",
    "        train_loss += loss.item() * input_ids.size(0)\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:41:06.454082Z",
     "iopub.status.busy": "2022-02-20T19:41:06.452968Z",
     "iopub.status.idle": "2022-02-20T19:41:06.472724Z",
     "shell.execute_reply": "2022-02-20T19:41:06.471688Z",
     "shell.execute_reply.started": "2022-02-20T19:41:06.454027Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, config):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    model.eval()  # prep model for evaluation\n",
    "    for batch in dataloader:\n",
    "        text, labels = batch\n",
    "        inputs = tokenizer.batch_encode_plus(\n",
    "            text, **config\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        token_type_ids = inputs['token_type_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # move things to model\n",
    "        output = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss_p = criterion(output, labels)\n",
    "        # update running validation loss\n",
    "        valid_loss += loss_p.item() * input_ids.size(0)\n",
    "        # calculate accuracy\n",
    "        proba = torch.exp(output)\n",
    "        top_p, top_class = proba.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        # accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return total, correct, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:41:08.890779Z",
     "iopub.status.busy": "2022-02-20T19:41:08.890527Z",
     "iopub.status.idle": "2022-02-20T19:41:08.895411Z",
     "shell.execute_reply": "2022-02-20T19:41:08.894648Z",
     "shell.execute_reply.started": "2022-02-20T19:41:08.89075Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "tokenizer_config = {\n",
    "    \"max_length\": 100,\n",
    "    \"padding\": \"max_length\",\n",
    "    \"return_tensors\": \"pt\",\n",
    "    \"truncation\": True,\n",
    "    \"add_special_tokens\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:41:11.077293Z",
     "iopub.status.busy": "2022-02-20T19:41:11.076713Z",
     "iopub.status.idle": "2022-02-20T19:58:35.407411Z",
     "shell.execute_reply": "2022-02-20T19:58:35.405915Z",
     "shell.execute_reply.started": "2022-02-20T19:41:11.077251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02506fd44dd449984d2fc70cbb8c755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 5.01 GiB already allocated; 0 bytes free; 5.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5892\\937643106.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Now Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5892\\1104667523.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, dataloader, criterion, config)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# move things to model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5892\\1340591815.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# pass the inputs to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m         )\n\u001b[1;32m-> 1021\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m   1022\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    608\u001b[0m                 )\n\u001b[0;32m    609\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[1;32m--> 426\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    427\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mcontext_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0mnew_context_layer_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_head_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_context_layer_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 5.01 GiB already allocated; 0 bytes free; 5.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_loss_data, valid_loss_data = [], []\n",
    "valid_loss_min = np.Inf\n",
    "since = time.time()\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}/{}\".format(epoch + 1, epochs))\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    e_since = time.time()\n",
    "\n",
    "    # Train Model\n",
    "    train_loss += train(model, train_dataloader, optimizer, criterion, tokenizer_config)\n",
    "    # Now Evaluate\n",
    "    out = evaluate(model, test_dataloader, criterion, tokenizer_config)\n",
    "    total += out[0]\n",
    "    correct += out[1]\n",
    "    valid_loss += out[2]\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # print training/validation statistics\n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss / len(train_dataloader.dataset)\n",
    "    valid_loss = valid_loss / len(test_dataloader.dataset)\n",
    "\n",
    "    # calculate train loss and running loss\n",
    "    train_loss_data.append(train_loss * 100)\n",
    "    valid_loss_data.append(valid_loss * 100)\n",
    "    \n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"news_model1.pth\")\n",
    "\n",
    "    print(\"\\tTrain loss:{:.6f}..\".format(train_loss),\n",
    "          \"\\tValid Loss:{:.6f}..\".format(valid_loss),\n",
    "          \"\\tAccuracy: {:.4f}\".format(correct / total * 100))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:58:35.409266Z",
     "iopub.status.busy": "2022-02-20T19:58:35.409031Z",
     "iopub.status.idle": "2022-02-20T19:58:35.631435Z",
     "shell.execute_reply": "2022-02-20T19:58:35.630716Z",
     "shell.execute_reply.started": "2022-02-20T19:58:35.409233Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_data, label=\"Training loss\")\n",
    "plt.plot(valid_loss_data, label=\"validation loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "To test this model, the left 15% data was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:58:49.849153Z",
     "iopub.status.busy": "2022-02-20T19:58:49.848843Z",
     "iopub.status.idle": "2022-02-20T19:58:50.301443Z",
     "shell.execute_reply": "2022-02-20T19:58:50.300676Z",
     "shell.execute_reply.started": "2022-02-20T19:58:49.84912Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./news_model1.pth\", map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:58:52.492508Z",
     "iopub.status.busy": "2022-02-20T19:58:52.492253Z",
     "iopub.status.idle": "2022-02-20T19:59:20.359704Z",
     "shell.execute_reply": "2022-02-20T19:59:20.358982Z",
     "shell.execute_reply.started": "2022-02-20T19:58:52.492479Z"
    }
   },
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    text, labels = batch\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        text, **tokenizer_config\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # move things to model\n",
    "    output = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n",
    "    preds = output.detach().cpu().numpy()\n",
    "    preds = np.argmax(preds, axis = 1)\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T19:59:20.361653Z",
     "iopub.status.busy": "2022-02-20T19:59:20.361403Z",
     "iopub.status.idle": "2022-02-20T19:59:20.37763Z",
     "shell.execute_reply": "2022-02-20T19:59:20.376529Z",
     "shell.execute_reply.started": "2022-02-20T19:59:20.361617Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thank you very much for reading.\n",
    "### পড়ার জন্য আপনাকে অনেক ধন্যবাদ।"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
