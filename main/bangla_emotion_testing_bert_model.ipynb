{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f9c5a0",
   "metadata": {},
   "source": [
    "# import #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719d0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d01938",
   "metadata": {},
   "source": [
    "# fnc #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1877a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "def train_test_debug():\n",
    "    if train_set[\"text\"][0] == training_data1[\"text\"][0]:\n",
    "        print(\"train set is ***1***\")\n",
    "    \n",
    "    if train_set[\"text\"][0] == training_data2[\"text\"][0]:\n",
    "        print(\"train set is ***2***\")\n",
    "        \n",
    "    if test_set[\"text\"][0] == testing_data1[\"text\"][0]:\n",
    "        print(\"test set is ***1***\")\n",
    "    \n",
    "    if test_set[\"text\"][0] == testing_data2[\"text\"][0]:\n",
    "        print(\"test set is ***2***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcdf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    if \",\" in text:\n",
    "        return str(text.replace(\",\",\"\"))\n",
    "    if \".\" in text:\n",
    "        return str(text.replace(\".\",\"\"))\n",
    "    if \"ред\" in text:\n",
    "        return str(text.replace(\"ред\",\"\"))\n",
    "    if \"|\" in text:\n",
    "        return str(text.replace(\"|\",\"\"))\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae497abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(emotion):\n",
    "    if emotion == \"happy\":\n",
    "        return 0\n",
    "    elif emotion == \"sad\":\n",
    "        return 1\n",
    "    elif emotion == \"angry\":\n",
    "        return 2\n",
    "    elif emotion == \"disgust\":\n",
    "        return 3\n",
    "    elif emotion == \"fear\":\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04afe232",
   "metadata": {},
   "source": [
    "# data #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab50943",
   "metadata": {},
   "source": [
    "**dataset1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data1 = pd.read_excel(\"all_data/training_DS1.xlsx\")\n",
    "print(training_data1.groupby(\"reaction\").apply(list))\n",
    "print(f\"shape = {training_data1.shape}\")\n",
    "print(f\"dtype = {training_data1.dtypes}\")\n",
    "print(f\"value count = \\n{training_data1['reaction'].value_counts()}\")\n",
    "\n",
    "training_list1 = training_data1.values.tolist()\n",
    "print(\"\\n\")\n",
    "testing_data1 = pd.read_excel(\"all_data/testing_DS1.xlsx\")\n",
    "print(testing_data1.groupby(\"reaction\").apply(list))\n",
    "print(f\"shape = {testing_data1.shape}\")\n",
    "print(f\"dtype = {testing_data1.dtypes}\")\n",
    "print(f\"value count = \\n{testing_data1['reaction'].value_counts()}\")\n",
    "\n",
    "testing_list1 = training_data1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data1[\"text\"] = training_data1[\"text\"].apply(clean_text)\n",
    "training_data1[\"label\"] = training_data1[\"reaction\"].apply(get_emotion)\n",
    "training_data1[\"num_of_words\"] = training_data1[\"text\"].apply(lambda x:len(str(x).split()))\n",
    "\n",
    "print(\"\\n split \\n\")\n",
    "\n",
    "testing_data1[\"text\"] = testing_data1[\"text\"].apply(clean_text)\n",
    "testing_data1[\"label\"] = testing_data1[\"reaction\"].apply(get_emotion)\n",
    "testing_data1[\"num_of_words\"] = testing_data1[\"text\"].apply(lambda x:len(str(x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec4840f",
   "metadata": {},
   "source": [
    "**dataset2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19372d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data2 = pd.read_excel(\"all_data/training_DS2.xlsx\")\n",
    "print(training_data2.groupby(\"reaction\").apply(list))\n",
    "print(f\"shape = {training_data2.shape}\")\n",
    "print(f\"dtype = {training_data2.dtypes}\")\n",
    "print(f\"value count = \\n{training_data2['reaction'].value_counts()}\")\n",
    "\n",
    "training_list2 = training_data2.values.tolist()\n",
    "print(\"\\n\")\n",
    "testing_data2 = pd.read_excel(\"all_data/testing_DS2.xlsx\")\n",
    "print(testing_data2.groupby(\"reaction\").apply(list))\n",
    "print(f\"shape = {testing_data2.shape}\")\n",
    "print(f\"dtype = {testing_data2.dtypes}\")\n",
    "print(f\"value count = \\n{testing_data2['reaction'].value_counts()}\")\n",
    "\n",
    "testing_list2 = training_data2.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a106e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data2[\"text\"] = training_data2[\"text\"].apply(clean_text)\n",
    "training_data2[\"label\"] = training_data2[\"reaction\"].apply(get_emotion)\n",
    "training_data2[\"num_of_words\"] = training_data2[\"text\"].apply(lambda x:len(str(x).split()))\n",
    "print(training_data2.groupby(\"reaction\").apply(list))\n",
    "\n",
    "print(\"\\n split \\n\")\n",
    "\n",
    "testing_data2[\"text\"] = testing_data2[\"text\"].apply(clean_text)\n",
    "testing_data2[\"label\"] = testing_data2[\"reaction\"].apply(get_emotion)\n",
    "testing_data2[\"num_of_words\"] = testing_data2[\"text\"].apply(lambda x:len(str(x).split()))\n",
    "print(training_data2.groupby(\"reaction\").apply(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8d1b4",
   "metadata": {},
   "source": [
    "**select dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31daaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = None\n",
    "test_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_train_test(train,test):\n",
    "    global train_set\n",
    "    global test_set\n",
    "    if train == 1 and test == 1:\n",
    "        print(\"train = 1 test = 1 loaded\")\n",
    "        print(testing_data1.groupby(\"reaction\").apply(list))\n",
    "        train_set = training_data1.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "        test_set = testing_data1.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "    elif train == 2 and test == 2:\n",
    "        print(\"train = 2 test = 2 loaded\")\n",
    "        print(training_data2.groupby(\"reaction\").apply(list))\n",
    "        train_set = training_data2.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "        test_set = testing_data2.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "    elif train == 1 and test == 2:\n",
    "        print(\"train = 1 test = 2 loaded\")\n",
    "        train_set = training_data1.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "        test_set = testing_data2.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "    elif train == 2 and test == 1:\n",
    "        print(\"train = 2 test = 1 loaded\")\n",
    "        train_set = training_data2.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "        test_set = testing_data1.drop(columns=[\"reaction\",\"num_of_words\"])\n",
    "    else:\n",
    "        print(\"choose between train 1/2 and test 1/2\")\n",
    "        \n",
    "    print(f\"value count = \\n{train_set['label'].value_counts()}\")\n",
    "    print(f\"value count = \\n{test_set['label'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b302a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d8232",
   "metadata": {},
   "source": [
    "# Select train test #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train_test(1,1)\n",
    "train_test_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train_test(2,2)\n",
    "train_test_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2438dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train_test(1,2)\n",
    "train_test_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720114eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train_test(2,1)\n",
    "train_test_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3accbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"csv_data/train.csv\")\n",
    "test_set = pd.read_csv(\"csv_data/test_set_2.csv\")\n",
    "# validate_set = pd.read_csv(\"csv_data/test_set_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a909b",
   "metadata": {},
   "source": [
    "# Model \"monsoon-nlp/bangla-electra\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7be5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationModel('bert', 'monsoon-nlp/bangla-electra', num_labels=5, use_cuda=True, args={\n",
    "    'reprocess_input_data': True,\n",
    "    'use_cached_eval_features': False,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 3,\n",
    "    'silent': True\n",
    "}) # , weight=[2.5, 1.0]\n",
    "model.train_model(train_set.sample(frac=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(test_set)\n",
    "bads = {}\n",
    "for pred in wrong_predictions:\n",
    "    if pred.label in bads:\n",
    "        bads[pred.label] += 1\n",
    "    else:\n",
    "        bads[pred.label] = 1\n",
    "print(\"wrong predictions:\")\n",
    "print(str(len(wrong_predictions)) + ' wrong out of ' + str(len(test_set)))\n",
    "print(f\"accuracy = {(len(test_set)-len(wrong_predictions))/len(test_set)*100}\")\n",
    "bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16151e",
   "metadata": {},
   "source": [
    "# Report monsoon-nlp/bangla-electra #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058eabf0",
   "metadata": {},
   "source": [
    "train set is ***1***\n",
    "test set is ***1***\n",
    "wrong predictions:\n",
    "474 wrong out of 1032\n",
    "accuracy = 54.06976744186046\n",
    "\n",
    "train set is ***2***\n",
    "test set is ***2***\n",
    "wrong predictions:\n",
    "628 wrong out of 1265\n",
    "accuracy = 50.35573122529644\n",
    "\n",
    "train set is ***1***\n",
    "test set is ***2***\n",
    "wrong predictions:\n",
    "874 wrong out of 1265\n",
    "accuracy = 30.909090909090907\n",
    "\n",
    "train set is ***2***\n",
    "test set is ***1***\n",
    "wrong predictions:\n",
    "699 wrong out of 1032\n",
    "accuracy = 32.26744186046512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866144ba",
   "metadata": {},
   "source": [
    "# Model \"sagorsarker/bangla-bert-base\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb2d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sagorsarker/bangla-bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\meera\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:612: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8400\\3637607551.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m'silent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m })\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mbert2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m                     \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 )\n\u001b[1;32m--> 619\u001b[1;33m             train_dataset = self.load_and_cache_examples(\n\u001b[0m\u001b[0;32m    620\u001b[0m                 \u001b[0mtrain_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[1;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[0;32m   1825\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1827\u001b[1;33m             dataset = ClassificationDataset(\n\u001b[0m\u001b[0;32m   1828\u001b[0m                 \u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mClassificationDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         self.examples, self.labels = build_classification_dataset(\n\u001b[0m\u001b[0;32m    283\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_utils.py\u001b[0m in \u001b[0;36mbuild_classification_dataset\u001b[1;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_count\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 examples = list(\n\u001b[0m\u001b[0;32m    250\u001b[0m                     tqdm(\n\u001b[0;32m    251\u001b[0m                         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_data_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;31m# (note: keep this check outside the loop for performance)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    856\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bert2 = ClassificationModel('bert', 'sagorsarker/bangla-bert-base', num_labels=5, use_cuda=True, args={\n",
    "    'reprocess_input_data': True,\n",
    "    'use_cached_eval_features': False,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 3,\n",
    "    'silent': True\n",
    "})\n",
    "bert2.train_model(train_set.sample(frac=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = bert2.eval_model(test_set)\n",
    "bads = {}\n",
    "for pred in wrong_predictions:\n",
    "    if pred.label in bads:\n",
    "        bads[pred.label] += 1\n",
    "    else:\n",
    "        bads[pred.label] = 1\n",
    "print(\"wrong predictions:\")\n",
    "print(str(len(wrong_predictions)) + ' wrong out of ' + str(len(test_set)))\n",
    "print(f\"accuracy = {(len(test_set)-len(wrong_predictions))/len(test_set)*100}\")\n",
    "bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0db012",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d58ff4",
   "metadata": {},
   "source": [
    "# Report sagorsarker/bangla-bert-base #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39078ab9",
   "metadata": {},
   "source": [
    "train set is ***1***\n",
    "test set is ***1***\n",
    "wrong predictions:\n",
    "214 wrong out of 1032\n",
    "accuracy = 79.26356589147287\n",
    "\n",
    "train set is ***2***\n",
    "test set is ***2***\n",
    "wrong predictions:\n",
    "185 wrong out of 1265\n",
    "accuracy = 85.37549407114624\n",
    "\n",
    "train set is ***1***\n",
    "test set is ***2***\n",
    "wrong predictions:\n",
    "722 wrong out of 1265\n",
    "accuracy = 42.92490118577075\n",
    "\n",
    "train set is ***2***\n",
    "test set is ***1***\n",
    "wrong predictions:\n",
    "578 wrong out of 1032\n",
    "accuracy = 43.992248062015506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1bf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "y_true = np.array(all_labels)\n",
    "y_pred = np.array(all_preds)\n",
    "print(precision_recall_fscore_support(y_true, y_pred, average='macro'))\n",
    "print(precision_recall_fscore_support(y_true, y_pred, average='micro'))\n",
    "print(precision_recall_fscore_support(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fe448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de637862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
